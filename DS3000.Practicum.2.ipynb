{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS 3000 - Practicum 2\n",
    "\n",
    "**Student Name**: Hwijoon Lee, Maya Karintholil, Sanya Mittal, and Shreyashi Kalakuntla\n",
    "\n",
    "**Date**: 2025-02-21\n",
    "\n",
    "\n",
    "### Submission Instructions\n",
    "Submit this `ipynb` file to canvas.\n",
    "\n",
    "The `ipynb` format stores outputs from the last time you ran the notebook.  (When you open a notebook it has the figures and outputs of the last time you ran it too).  To ensure that your submitted `ipynb` file represents your latest code, make sure to give a fresh run `Kernel > Restart & Run All` just before uploading the `ipynb` file to Canvas.\n",
    "\n",
    "### Academic Integrity\n",
    "\n",
    "**Writing your homework is an individual effort.**  You may discuss general python problems with other students but under no circumstances should you observe another student's code which was written for this assignment, from this year or past years.  Pop into office hours or DM us in MS Teams if you have a specific question about your work or if you would like another pair of eyes or talk through your code.\n",
    "\n",
    "Don't forget to cite websites which helped you solve a problem in a unique way.  You can do this in markdown near the code or with a simple one-line comment. You do not need to cite the official python documentation.\n",
    "\n",
    "**Documentation / style counts for credit**  Please refer to the Pep-8 style, to improve the readability and consistency of your Python code. For more information, read the following article [How to Write Beautiful Python Code With PEP 8](https://realpython.com/python-pep8/) or ask your TA's for tips.\n",
    "\n",
    "**NOTE:<span style='color:red'> Write python expressions to answer ALL questions below and ensure that you use the `print()` function to display the output.</span>** Each question should be answered in a new code cell. For example, your solution for question 1.1 should be in a different code cell from your solution for question 1.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: \n",
    "\n",
    "In your own words, formulate the Data Science problem that you were given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your python code to answer question 1. You can add new cells below as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: \n",
    "Load the data using pandas and inspect it.\n",
    "\n",
    "Perform the initial inspection of the data, its shape, types, etc.\n",
    "Evaluate the dataset and perform at least three type of data preparation and justify the approach that is taken to prepare the data for analysis. Data prep can include, but is not limited to: handling missing values, data types, duplicates, etc. You will need to ensure that your data preparation addressed issues in at least 7 fields in the data.\n",
    "Prepare meaningful* summary statistics for 3 continuous variables and 3 categorical variables.\n",
    "Note: meaningful summary statistics explains the statistical summary of relevant fields in a coherent manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dw/7lckm6l56sn70yq_dk59qxbr0000gn/T/ipykernel_4521/2048397694.py:4: DtypeWarning: Columns (18,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('Bird_Strikes_1990_2023.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('Bird_Strikes_1990_2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in each column:\n",
      "INDEX_NR               0\n",
      "INCIDENT_DATE          0\n",
      "INCIDENT_MONTH         0\n",
      "INCIDENT_YEAR          0\n",
      "TIME              125177\n",
      "                   ...  \n",
      "REPORTED_TITLE         0\n",
      "SOURCE                 0\n",
      "PERSON             21134\n",
      "LUPDATE                0\n",
      "TRANSFER               0\n",
      "Length: 100, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing values in each column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Convert INCIDENT_DATE to datetime type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['INCIDENT_DATE'] = pd.to_datetime(df['INCIDENT_DATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Handle missing values filling in Unknown for categorical variables and median for numeric variables\n",
    "- We use median instead of mean because Median is less sensitive to extreme outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing numeric values\n",
    "df['LATITUDE'] = df['LATITUDE'].fillna(df['LATITUDE'].median())\n",
    "df['LONGITUDE'] = df['LONGITUDE'].fillna(df['LONGITUDE'].median())\n",
    "df['DISTANCE'] = df['DISTANCE'].fillna(df['DISTANCE'].median())\n",
    "\n",
    "# Fill missing categorical values\n",
    "df['STATE'] = df['STATE'].fillna('Unknown')\n",
    "df['FAAREGION'] = df['FAAREGION'].fillna('Unknown')\n",
    "df['TIME_OF_DAY'] = df['TIME_OF_DAY'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Removing completely empty columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before removal:\n",
      "Number of columns: 100\n",
      "\n",
      "Non-null value counts for specific columns:\n",
      "LUPDATE: 288810\n",
      "TRANSFER: 288810\n",
      "\n",
      "Total number of rows: 288810\n",
      "\n",
      "After removal:\n",
      "Number of columns: 98\n"
     ]
    }
   ],
   "source": [
    "print(\"Before removal:\")\n",
    "print(\"Number of columns:\", len(df.columns))\n",
    "\n",
    "print(\"\\nNon-null value counts for specific columns:\")\n",
    "print(\"LUPDATE:\", df['LUPDATE'].count())\n",
    "print(\"TRANSFER:\", df['TRANSFER'].count())\n",
    "\n",
    "print(\"\\nTotal number of rows:\", len(df))\n",
    "\n",
    "# Remove unnecessary columns and duplicates\n",
    "columns_to_drop = ['LUPDATE', 'TRANSFER']\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "print(\"\\nAfter removal:\")\n",
    "print(\"Number of columns:\", len(df.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Summary Statistics for Continuous Variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Statistics for Continuous Variables:\n",
      "           LATITUDE      LONGITUDE       DISTANCE\n",
      "count  2.888100e+05  288810.000000  288810.000000\n",
      "mean   1.813044e+02     -90.514448       0.530834\n",
      "std    7.658451e+04     306.472863       2.890473\n",
      "min   -3.767333e+01    -177.381000       0.000000\n",
      "25%    3.367566e+01     -97.362440       0.000000\n",
      "50%    3.880581e+01     -87.904460       0.000000\n",
      "75%    4.077724e+01     -81.316030       0.000000\n",
      "max    4.115443e+07  164140.000000      99.000000\n"
     ]
    }
   ],
   "source": [
    "continuous_vars = ['LATITUDE', 'LONGITUDE', 'DISTANCE']\n",
    "print(\"\\nSummary Statistics for Continuous Variables:\")\n",
    "print(df[continuous_vars].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuous Variables:\n",
    "- The geographic data shows LATITUDE and LONGITUDE contain outliers beyond valid ranges, requiring cleanup before spatial analysis. \n",
    "- DISTANCE measurements reveal most bird strikes (over 50%) occur at 0 distance from airports, with values ranging up to 99 units.\n",
    "\n",
    "#### Further clearning for Latitude and Longitude\n",
    "- Latidue contains outliers beyond valid ranges, requiring cleanup before spatial analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Geographic Coordinates Summary:\n",
      "            LATITUDE      LONGITUDE\n",
      "count  288810.000000  288810.000000\n",
      "mean       37.108369     -91.083085\n",
      "std         6.419505      23.152147\n",
      "min       -37.673333    -177.381000\n",
      "25%        33.675660     -97.362440\n",
      "50%        38.805810     -87.904460\n",
      "75%        40.777240     -81.316030\n",
      "max        71.285450     178.559228\n"
     ]
    }
   ],
   "source": [
    "df['LATITUDE'] = df['LATITUDE'].apply(\n",
    "    lambda x: x if (-90 <= x <= 90) else df['LATITUDE'].median()\n",
    ")\n",
    "df['LONGITUDE'] = df['LONGITUDE'].apply(\n",
    "    lambda x: x if (-180 <= x <= 180) else df['LONGITUDE'].median()\n",
    ")\n",
    "\n",
    "# Display cleaned summary statistics\n",
    "print(\"Cleaned Geographic Coordinates Summary:\")\n",
    "print(df[['LATITUDE', 'LONGITUDE']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Summary Statistics for Categorical Variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Statistics for Categorical Variables:\n",
      "\n",
      "Value counts for STATE:\n",
      "STATE\n",
      "Unknown    35501\n",
      "TX         24794\n",
      "FL         20616\n",
      "CA         20431\n",
      "NY         14371\n",
      "Name: count, dtype: int64\n",
      "Number of unique values: 68\n",
      "\n",
      "Value counts for FAAREGION:\n",
      "FAAREGION\n",
      "ASO        53932\n",
      "AEA        40845\n",
      "AGL        39773\n",
      "Unknown    35501\n",
      "ASW        33354\n",
      "Name: count, dtype: int64\n",
      "Number of unique values: 11\n",
      "\n",
      "Value counts for TIME_OF_DAY:\n",
      "TIME_OF_DAY\n",
      "Unknown    122416\n",
      "Day        102548\n",
      "Night       50446\n",
      "Dusk         7428\n",
      "Dawn         5972\n",
      "Name: count, dtype: int64\n",
      "Number of unique values: 5\n"
     ]
    }
   ],
   "source": [
    "categorical_vars = ['STATE', 'FAAREGION', 'TIME_OF_DAY']\n",
    "print(\"\\nSummary Statistics for Categorical Variables:\")\n",
    "for var in categorical_vars:\n",
    "    print(f\"\\nValue counts for {var}:\")\n",
    "    print(df[var].value_counts().head())\n",
    "    print(f\"Number of unique values: {df[var].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical Variables: \n",
    "- Texas, Florida, and California report the highest number of incidents among states, with 68 unique states/territories recorded. \n",
    "- The FAA regions show ASO (Southern) leading with 53,932 incidents, followed by AEA (Eastern) with 40,845. \n",
    "- TIME_OF_DAY analysis reveals most incidents occur during Unknown and Day periods, with 5 distinct time categories identified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: \n",
    "Perform an in-depth analysis by creating visualizations to understand the distribution and relationships within the data, while ensuring that your analysis and explanation of the results tell a story. It's important to select appropriate visualizations based on the type of data. Explain all results.\n",
    "\n",
    "Analyze the proportion of incidents that occur each year.\n",
    "Evaluate the distribution of bird strikes in each state and display the top 20 states.\n",
    "What is the most common bird species that are involved in bird strikes.\n",
    "Perform a comparative analysis of the annual aircraft damage for each phase of flight. Evaluate the results over the last 10 years to determine what patterns exist. Note: this requires a year over year analysis.\n",
    "Analyze the frequency of bird strike incidents that occur on a monthly basis over the last 10 years. Analyze the results to determine when these incidents are more prevalent.  This question requires you to drill deeper into the analysis to determine if the distribution has changed over the last 10 years. Note: this requires a year over year analysis.\n",
    "Perform ONE (1) additional analysis on the distribution. \n",
    "\n",
    "Ensure that you either : 1. perform a comparative analysis by evaluating 3 or more groups within the data or 2. perform a temporal analysis of the patterns over 10 or more years (this requires a year over year analysis of the patterns). Do not repeat any of the previous analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: \n",
    "Perform pairwise analysis of select features and evaluate the significance of the pattern or trend. A suitable value for alpha is 5%. Explain all results.\n",
    "\n",
    "Create a scatterplot that shows the relationship between aircraft height and speed. Evaluate the correlation, the strength and the significance of the results.\n",
    "Visualize the distribution of the aircraft speed during: 1. the approach phase of flight and 2. the landing roll phase of flight. Perform a 2 sample t-test and evaluate if there is a statistical difference between the speed during these two flight phases. Tip: if the data is skewed, you will need to address this prior to the statistical analysis.\n",
    "Create a visualization of the aircraft damage grouped by phase of flight.\n",
    "Evaluate if the results are statistically significant. Ensure that you use the appropriate test.\n",
    "Perform ONE (1) additional statistical test.\n",
    "Explain what you are testing and the reason this information is useful.\n",
    "Visualize the data, state the hypothesis and explain if it is statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: \n",
    "Explore a simple linear relationship* within the data and create a model to predict the occurrence of bird strikes in a given FAA region. Ensure that you explain all results.\n",
    "\n",
    "Extract all data for the AWP FAA Region and use a line chart to visualize the frequency of incidents between 1990 and 2015 inclusive.\n",
    "Using the extracted data above, create a simple linear regression model and predicts the incidents for 2016 and 2017.\n",
    "Display the r-squared and what this indicates about your model's ability to fit the data.\n",
    "Visualize the dataset from (1) and include the predicted results for 2016 and 2017.\n",
    "Compare and contrast the predictions for 2016 and 2017 with the actual values.\n",
    "Perform predictions for 2018 through to 2020. Explain what transpired when your model was used to predict this time period. Comment on the reliability of your model.\n",
    "*Tip: It is important to remember that you are creating a simple linear regression model, which is limited in features and does not include information about all factors that influence the frequency of bird strikes. Keep this in mind while framing your response and explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6: \n",
    "Summarize the overall analysis for questions 1 through 5 and share THREE (3) key findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpful resources \n",
    "Don't forget to cite websites which helped you solve a problem in a unique way.  You can do this in markdown near the code or with a simple one-line comment inside the code cell, or you can list them below. \n",
    "\n",
    "You do not need to cite the official python documentation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
